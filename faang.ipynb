{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. Information': 'Intraday (15min) open, high, low, close prices and volume',\n",
       " '2. Symbol': 'FB',\n",
       " '3. Last Refreshed': '2019-03-29 16:00:00',\n",
       " '4. Interval': '15min',\n",
       " '5. Output Size': 'Compact',\n",
       " '6. Time Zone': 'US/Eastern'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_KEY = 'PZZ6AOYX66Q8H83Q'\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas', indexing_type='date')\n",
    "data, meta_data = ts.get_intraday('FB')\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/FAANG_13_18_CSV.csv')\n",
    "df.columns = ['PermNo', 'Date', 'Ticker', 'Low', 'High', 'Close', 'Volume', 'Open']\n",
    "df['Date'] = pd.to_datetime(df.Date, format='%m/%d/%Y')\n",
    "df = df.sort_values(['Date'])\n",
    "fb_df = df[df.Ticker == 'FB']\n",
    "aapl_df = df[df.Ticker == 'AAPL']\n",
    "amzn_df = df[df.Ticker == 'AMZN']\n",
    "nflx_df = df[df.Ticker == 'NFLX']\n",
    "googl_df = df[df.Ticker == 'GOOGL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, training_window=5, prediction_window=3):\n",
    "    data = df['High'].values\n",
    "    training_size = math.floor(0.9 * len(data))\n",
    "    test_size = len(data) - training_size\n",
    "    train_data = data[0:training_size]\n",
    "    test_data = data[training_size:]\n",
    "    \n",
    "    train_data = train_data.reshape(-1, 1)\n",
    "    test_data = test_data.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_data)\n",
    "    \n",
    "    train_data = scaler.transform(train_data)\n",
    "    test_data = scaler.transform(test_data)\n",
    "    \n",
    "    train_data = train_data.reshape(-1)\n",
    "    test_data = test_data.reshape(-1)\n",
    "    \n",
    "    x_train, y_train, x_val, y_val = [], [], [], []\n",
    "\n",
    "    for i in range(0, training_size - prediction_window - training_window + 1):\n",
    "        x_train.append(train_data[i:i+training_window])\n",
    "        y_train.append(train_data[i+training_window:i+training_window+prediction_window])\n",
    "    \n",
    "    for i in range(0, test_size - prediction_window - training_window + 1):\n",
    "        x_val.append(test_data[i:i+training_window])\n",
    "        y_val.append(test_data[i+training_window:i+training_window+prediction_window])\n",
    "        \n",
    "    return np.asarray(x_train), np.asarray(y_train), np.asarray(x_val), np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, device, prediction_window, batch_size=1, p=0):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        \n",
    "        ################### Model Properties ####################\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.p = p\n",
    "        self.batch_size = batch_size\n",
    "        self.prediction_window = prediction_window\n",
    "        self.device = device\n",
    "        #########################################################\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, dropout=self.p)\n",
    "        self.hidden_states = self.initialize_hidden_states()\n",
    "        self.output = nn.Linear(self.hidden_size, self.prediction_window)\n",
    "        \n",
    "    def initialize_hidden_states(self):\n",
    "        return (torch.zeros((self.num_layers, self.batch_size, self.hidden_size), device=self.device),\n",
    "                torch.zeros((self.num_layers, self.batch_size, self.hidden_size), device=self.device))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is of shape torch.size([batch_size, training_window])\n",
    "        model_in = torch.tensor(x, dtype=torch.float, device=self.device).view(x.shape[1], self.batch_size, self.input_size)\n",
    "        lstm_out, self.hidden_states = self.lstm(model_in, self.hidden_states)\n",
    "        \n",
    "        # Need the output of the last timestep of the LSTM only \n",
    "        prediction = self.output(lstm_out[-1].view(self.batch_size, -1))\n",
    "        \n",
    "        return prediction\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchIterator(object):\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.x = data[0]\n",
    "        self.y = data[1]\n",
    "        self.batch_size = batch_size\n",
    "        self.low = 0\n",
    "        self.high = batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return (self.x[i], self.y[i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.low >= len(self):\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            batch_x = self.x[self.low : self.high] if self.high < len(self.x) else self.x[self.low:]\n",
    "            batch_y = self.y[self.low : self.high] if self.high < len(self.y) else self.y[self.low:]\n",
    "            self.low += self.batch_size\n",
    "            self.high += self.batch_size\n",
    "            return batch_x, batch_y\n",
    "    \n",
    "    def reset(self):\n",
    "        self.low = 0\n",
    "        self.high = self.batch_size\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "input_size = 1\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "prediction_window = 3\n",
    "training_window = 10\n",
    "dropout=0.2\n",
    "epochs = 40\n",
    "\n",
    "x_train, y_train, x_val, y_val = load_data(fb_df, training_window=training_window, prediction_window=prediction_window)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dev_cpu = torch.device(\"cpu\")\n",
    "net = StockPredictor(input_size, hidden_size, num_layers, device, prediction_window, batch_size=batch_size, p=0.2)\n",
    "train_itr = BatchIterator((x_train, y_train), batch_size)\n",
    "val_itr = BatchIterator((x_val, y_val), batch_size)\n",
    "\n",
    "loss_function = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Average loss:0.0018392401980236173\n",
      "Average test MSE = 0.03420280585943912\n",
      "Epoch:1, Average loss:0.010904445312917233\n",
      "Average test MSE = 0.034379753994572444\n",
      "Epoch:2, Average loss:0.013457505963742733\n",
      "Average test MSE = 0.034185560574914675\n",
      "Epoch:3, Average loss:0.012979981489479542\n",
      "Average test MSE = 0.03256920246029041\n",
      "Epoch:4, Average loss:0.014227927662432194\n",
      "Average test MSE = 0.03083106111451062\n",
      "Epoch:5, Average loss:0.01500963419675827\n",
      "Average test MSE = 0.03134741359539339\n",
      "Epoch:6, Average loss:0.013699657283723354\n",
      "Average test MSE = 0.030432446186764103\n",
      "Epoch:7, Average loss:0.015362556092441082\n",
      "Average test MSE = 0.033107143878541294\n",
      "Epoch:8, Average loss:0.018753657117486\n",
      "Average test MSE = 0.03075031483160859\n",
      "Epoch:9, Average loss:0.01699778623878956\n",
      "Average test MSE = 0.029459110320427105\n",
      "Epoch:10, Average loss:0.01687926985323429\n",
      "Average test MSE = 0.03278120037677338\n",
      "Epoch:11, Average loss:0.027460768818855286\n",
      "Average test MSE = 0.023753502727915172\n",
      "Epoch:12, Average loss:0.029766632243990898\n",
      "Average test MSE = 0.028690619204855116\n",
      "Epoch:13, Average loss:0.026484915986657143\n",
      "Average test MSE = 0.030762484309531338\n",
      "Epoch:14, Average loss:0.022582001984119415\n",
      "Average test MSE = 0.03355521302738268\n",
      "Epoch:15, Average loss:0.018640680238604546\n",
      "Average test MSE = 0.03547230177547883\n",
      "Epoch:16, Average loss:0.022814851254224777\n",
      "Average test MSE = 0.020183581268808613\n",
      "Epoch:17, Average loss:0.026432564482092857\n",
      "Average test MSE = 0.019728781824943333\n",
      "Epoch:18, Average loss:0.026571493595838547\n",
      "Average test MSE = 0.021347243192560574\n",
      "Epoch:19, Average loss:0.0275441762059927\n",
      "Average test MSE = 0.030098985384157208\n",
      "Epoch:20, Average loss:0.02102244272828102\n",
      "Average test MSE = 0.03247196261690524\n",
      "Epoch:21, Average loss:0.01330987922847271\n",
      "Average test MSE = 0.03476769124953631\n",
      "Epoch:22, Average loss:0.01908932253718376\n",
      "Average test MSE = 0.03249871525938001\n",
      "Epoch:23, Average loss:0.019917836412787437\n",
      "Average test MSE = 0.025100730268148012\n",
      "Epoch:24, Average loss:0.024033136665821075\n",
      "Average test MSE = 0.031831585029015654\n",
      "Epoch:25, Average loss:0.022227171808481216\n",
      "Average test MSE = 0.03558081289084578\n",
      "Epoch:26, Average loss:0.020400550216436386\n",
      "Average test MSE = 0.03479501666342353\n",
      "Epoch:27, Average loss:0.0192535612732172\n",
      "Average test MSE = 0.03178308042428094\n",
      "Epoch:28, Average loss:0.022481845691800117\n",
      "Average test MSE = 0.02622504506764291\n",
      "Epoch:29, Average loss:0.021912209689617157\n",
      "Average test MSE = 0.03122398233482998\n",
      "Epoch:30, Average loss:0.016755325719714165\n",
      "Average test MSE = 0.03218114055837717\n",
      "Epoch:31, Average loss:0.01775318942964077\n",
      "Average test MSE = 0.0329047343083418\n",
      "Epoch:32, Average loss:0.018219495192170143\n",
      "Average test MSE = 0.02822819849487835\n",
      "Epoch:33, Average loss:0.015892140567302704\n",
      "Average test MSE = 0.025167635581172722\n",
      "Epoch:34, Average loss:0.0123514449223876\n",
      "Average test MSE = 0.026499576177121197\n",
      "Epoch:35, Average loss:0.026872247457504272\n",
      "Average test MSE = 0.02465530727857942\n",
      "Epoch:36, Average loss:0.024989623576402664\n",
      "Average test MSE = 0.025992983756430083\n",
      "Epoch:37, Average loss:0.02245699055492878\n",
      "Average test MSE = 0.03347320464495719\n",
      "Epoch:38, Average loss:0.022923119366168976\n",
      "Average test MSE = 0.029896964646534678\n",
      "Epoch:39, Average loss:0.018929949030280113\n",
      "Average test MSE = 0.02733909804396958\n",
      "************ Finished Training **************\n",
      "Minimum test MSE = 0.019728781824943333\n",
      "Saving best model..\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "min_test_mse = 200 # Arbitrary value larger than the largest error\n",
    "for epoch in range(epochs):\n",
    "    i = 0\n",
    "    train_itr.reset()\n",
    "    val_itr.reset()\n",
    "    avg_loss = 0\n",
    "    test_mse = 0\n",
    "    net.train()\n",
    "    for x, y in train_itr:\n",
    "        net.zero_grad()\n",
    "        net.hidden_states = net.initialize_hidden_states()\n",
    "        \n",
    "        y_pred = net(x)\n",
    "        y_true = torch.tensor(y, dtype=torch.float, device=device)\n",
    "        \n",
    "        loss = loss_function(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss\n",
    "        i += 1\n",
    "\n",
    "    print('Epoch:{}, Average loss:{}'.format(epoch, avg_loss/i))\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    num_val = 0\n",
    "    net.eval()\n",
    "    for x, y_true in val_itr:\n",
    "        y_pred = net(x).cpu().detach().numpy()\n",
    "        test_mse += (np.square(y_true - y_pred)).mean(axis=1).item()\n",
    "        num_val += 1\n",
    "    \n",
    "    test_mse /= num_val\n",
    "    print('Average test MSE = {}'.format(test_mse))\n",
    "    \n",
    "    if test_mse < min_test_mse:\n",
    "        del best_model_params\n",
    "        min_test_mse = test_mse\n",
    "        best_model_params = copy.deepcopy(net.state_dict())\n",
    "\n",
    "print('************ Finished Training **************')\n",
    "print('Minimum test MSE = {}'.format(min_test_mse))\n",
    "print('Saving best model..')\n",
    "torch.save(best_model_params, './models/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully loaded model ./models/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./models/best_model.pt'))\n",
    "net.eval()\n",
    "print('Sucessfully loaded model {}'.format('./models/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test MSE = 0.019728801922865944\n"
     ]
    }
   ],
   "source": [
    "num_val = 0\n",
    "val_itr.reset()\n",
    "test_mse = 0\n",
    "for x, y_true in val_itr:\n",
    "    y_pred = net(x).cpu().detach().numpy()\n",
    "    test_mse += (np.square(y_true - y_pred)).mean(axis=1).item()\n",
    "    num_val += 1\n",
    "\n",
    "test_mse /= num_val\n",
    "print('Average test MSE = {}'.format(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75434002 0.74232127 0.72385753 0.7080647  0.70713577 0.7112001\n",
      " 0.70690352 0.68907852 0.66573764 0.64488872]\n",
      "[[0.75434002 0.74232127 0.72385753 0.7080647  0.70713577 0.7112001\n",
      "  0.70690352 0.68907852 0.66573764 0.64488872]]\n",
      "tensor([[0.8814, 0.8869, 0.8915]], grad_fn=<AddmmBackward>)\n",
      "[0.66248617 0.64686752 0.661383  ]\n"
     ]
    }
   ],
   "source": [
    "x = x_val[115].reshape(1, -1)\n",
    "print(x_val[115])\n",
    "print(x)\n",
    "y_pred = net(x)\n",
    "print(y_pred)\n",
    "print(y_val[115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: True, 2: False}\n",
      "{1: True, 2: False}\n"
     ]
    }
   ],
   "source": [
    "a = {1 : True, 2 : False}\n",
    "\n",
    "if True:\n",
    "    del b\n",
    "    b = copy.deepcopy(a)\n",
    "\n",
    "print(b)\n",
    "a[1] = False\n",
    "    \n",
    "if False:\n",
    "    print('Entered')\n",
    "    b = a\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
